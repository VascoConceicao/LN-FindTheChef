{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c81e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config (run before anything else)\n",
    "LOG_RESULTS = True\n",
    "N_SPLITS = 5\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=r\"unknown class\\(es\\).*will be ignored\",\n",
    "    module=\"sklearn.preprocessing._label\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b399724",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "### Text Features:\n",
    "\n",
    "Experiment with `TfidfVectorizer` parameters (e.g., `ngram_range`, `min_df`, `max_df`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992e895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/strong_baseline/folds_preprocessed.csv)\n",
      "  Fold 1: 0.8533\n",
      "  Fold 2: 0.8533\n",
      "  Fold 3: 0.8483\n",
      "  Fold 4: 0.8433\n",
      "  Fold 5: 0.8447\n",
      "Mean accuracy: 0.8486  |  Std: 0.0047\n",
      "Total runtime: 15.07 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (preprocessed data) | Text | Baseline (Unigrams only)'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/strong_baseline/folds_preprocessed.csv)\n",
      "  Fold 1: 0.8883\n",
      "  Fold 2: 0.8767\n",
      "  Fold 3: 0.8767\n",
      "  Fold 4: 0.8617\n",
      "  Fold 5: 0.8564\n",
      "Mean accuracy: 0.8720  |  Std: 0.0128\n",
      "Total runtime: 45.94 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (preprocessed data) | Text | Unigrams + Bigrams'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/strong_baseline/folds_preprocessed.csv)\n",
      "  Fold 1: 0.8633\n",
      "  Fold 2: 0.8550\n",
      "  Fold 3: 0.8450\n",
      "  Fold 4: 0.8450\n",
      "  Fold 5: 0.8464\n",
      "Mean accuracy: 0.8509  |  Std: 0.0081\n",
      "Total runtime: 13.40 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (preprocessed data) | Text | Unigrams, ignore very rare terms (min_df=5)'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/strong_baseline/folds_preprocessed.csv)\n",
      "  Fold 1: 0.8567\n",
      "  Fold 2: 0.8567\n",
      "  Fold 3: 0.8500\n",
      "  Fold 4: 0.8450\n",
      "  Fold 5: 0.8447\n",
      "Mean accuracy: 0.8506  |  Std: 0.0059\n",
      "Total runtime: 13.95 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (preprocessed data) | Text | Unigrams, ignore very common terms (max_df=0.9)'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/strong_baseline/folds_preprocessed.csv)\n",
      "  Fold 1: 0.8933\n",
      "  Fold 2: 0.8800\n",
      "  Fold 3: 0.8867\n",
      "  Fold 4: 0.8617\n",
      "  Fold 5: 0.8548\n",
      "Mean accuracy: 0.8753  |  Std: 0.0165\n",
      "Total runtime: 26.96 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (preprocessed data) | Text | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "\n",
      "================================================================================\n",
      "        Linear SVC — TF-IDF Configs (Preprocessed) (Top 10)\n",
      "================================================================================\n",
      "                                                                                 Algorithm  Accuracy  Training_Time_s\n",
      "0          Linear SVC (preprocessed data) | Text | Unigrams + Bigrams, with term filtering  0.875285        26.955442\n",
      "1                               Linear SVC (preprocessed data) | Text | Unigrams + Bigrams  0.871952        45.936576\n",
      "2      Linear SVC (preprocessed data) | Text | Unigrams, ignore very rare terms (min_df=5)  0.850949        13.403614\n",
      "3  Linear SVC (preprocessed data) | Text | Unigrams, ignore very common terms (max_df=0.9)  0.850615        13.948994\n",
      "4                         Linear SVC (preprocessed data) | Text | Baseline (Unigrams only)  0.848615        15.069983\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from utils import run_configs, print_results_table\n",
    "\n",
    "# Path to folds file\n",
    "FOLDS_PATH = \"data/strong_baseline/folds_preprocessed.csv\"\n",
    "\n",
    "# Parameter grid\n",
    "tfidf_configs = [\n",
    "    {\n",
    "        \"description\": \"Baseline (Unigrams only)\",\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"min_df\": 1,\n",
    "        \"max_df\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Unigrams + Bigrams\",\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 1,\n",
    "        \"max_df\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Unigrams, ignore very rare terms (min_df=5)\",\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"min_df\": 5,\n",
    "        \"max_df\": 1.0,\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Unigrams, ignore very common terms (max_df=0.9)\",\n",
    "        \"ngram_range\": (1, 1),\n",
    "        \"min_df\": 1,\n",
    "        \"max_df\": 0.9,\n",
    "    },\n",
    "    {\n",
    "        \"description\": \"Unigrams + Bigrams, with term filtering\",\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 5,\n",
    "        \"max_df\": 0.9,\n",
    "    },\n",
    "]\n",
    "\n",
    "results = run_configs(\n",
    "    models=[(SVC, {\"kernel\": \"linear\"}, \"Linear SVC\")],\n",
    "    folds_path=FOLDS_PATH,\n",
    "    tfidf_configs=tfidf_configs,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    log_results=LOG_RESULTS,\n",
    ")\n",
    "\n",
    "print_results_table(\n",
    "    results, title=\"Linear SVC — TF-IDF Configs (Preprocessed)\", top_n=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94834821",
   "metadata": {},
   "source": [
    "### Numerical Features:\n",
    "\n",
    "Use the `n_ingredients` column. We could also create new features like the number of steps, length of the description, etc. We may need to combine these with the TF-IDF features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3268e802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original dataset from 'data/train.csv'...\n",
      "Starting feature engineering...\n",
      "Created new features: 'description_len' and 'n_steps'.\n",
      "Top 5 rows with new features:\n",
      "   n_ingredients  description_len  n_steps\n",
      "0              6               38        7\n",
      "1             13               85       16\n",
      "2             12               57       13\n",
      "3              4               61        2\n",
      "4             13              128       31\n",
      "\n",
      "Preprocessing text data...\n",
      "\n",
      "Creating stratified folds via create_folds...\n",
      "\n",
      "==================================================\n",
      "## Chef ID Distribution Check\n",
      "\n",
      "=== Original Dataset === (Size: 2999)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       806       26.88\n",
      "5060       534       17.81\n",
      "3288       451       15.04\n",
      "8688       432       14.40\n",
      "1533       404       13.47\n",
      "6357       372       12.40\n",
      "\n",
      "=== Fold 1 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        86       14.33\n",
      "1533        81       13.50\n",
      "6357        75       12.50\n",
      "\n",
      "=== Fold 2 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       162       27.00\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        86       14.33\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 3 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        87       14.50\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 4 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        87       14.50\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 5 === (Size: 599)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.88\n",
      "5060       106       17.70\n",
      "3288        91       15.19\n",
      "8688        86       14.36\n",
      "1533        80       13.36\n",
      "6357        75       12.52\n",
      "==================================================\n",
      "\n",
      "Folds saved to 'data/feature_engineering/folds_numerical.csv' (Total: 2999 rows)\n",
      "\n",
      "Running K-Fold experiment with Linear SVC on document + numeric features...\n",
      "\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_numerical.csv)\n",
      "  Fold 1: 0.6950\n",
      "  Fold 2: 0.6417\n",
      "  Fold 3: 0.7033\n",
      "  Fold 4: 0.6817\n",
      "  Fold 5: 0.6912\n",
      "Mean accuracy: 0.6826  |  Std: 0.0242\n",
      "Total runtime: 2.99 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (numerical data) | Text + Numerical | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from utils import run_kfold_experiment, create_folds\n",
    "\n",
    "# config\n",
    "ORIGINAL_DATA_PATH = \"data/train.csv\"\n",
    "FOLDS_PATH = \"data/feature_engineering/folds_numerical.csv\"\n",
    "\n",
    "# using best parameters identified from previous experiment for better performance\n",
    "TFIDF_CFG = {\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"min_df\": 5,\n",
    "    \"max_df\": 0.9,\n",
    "}\n",
    "\n",
    "# data loading and feature engineering\n",
    "print(f\"Loading original dataset from '{ORIGINAL_DATA_PATH}'...\")\n",
    "try:\n",
    "    data = pd.read_csv(ORIGINAL_DATA_PATH, sep=\";\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Original data file not found at '{ORIGINAL_DATA_PATH}'.\")\n",
    "    print(\"This script needs the raw dataset to create numerical features.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Starting feature engineering...\")\n",
    "\n",
    "# fill NaNs in key columns\n",
    "data[\"description\"] = data[\"description\"].fillna(\"\")\n",
    "data[\"steps\"] = data[\"steps\"].fillna(\"[]\")\n",
    "data[\"n_ingredients\"] = data[\"n_ingredients\"].fillna(0)\n",
    "\n",
    "# create 'description_len' feature\n",
    "data[\"description_len\"] = data[\"description\"].str.len()\n",
    "\n",
    "\n",
    "# create 'n_steps' feature\n",
    "# evaluate 'steps' string to a list and get its length\n",
    "def count_steps(step_string):\n",
    "    try:\n",
    "        return len(re.findall(r\"\\'(.*?)\\'\", str(step_string)))\n",
    "    except (TypeError, ValueError):\n",
    "        return 0\n",
    "\n",
    "\n",
    "data[\"n_steps\"] = data[\"steps\"].apply(count_steps)\n",
    "print(f\"Created new features: 'description_len' and 'n_steps'.\")\n",
    "print(\"Top 5 rows with new features:\")\n",
    "print(data[[\"n_ingredients\", \"description_len\", \"n_steps\"]].head())\n",
    "\n",
    "# text preprocessing\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "try:\n",
    "    stopwords.words(\"english\")\n",
    "except LookupError:\n",
    "    print(\"Stopwords not found. Downloading...\")\n",
    "    nltk.download(\"stopwords\")\n",
    "stop_words_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "# same cleaning steps as before\n",
    "data[\"description_processed\"] = (\n",
    "    data[\"description\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z\\s]\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .apply(lambda text: \" \".join(w for w in text.split() if w not in stop_words_set))\n",
    ")\n",
    "\n",
    "numerical_features = [\"n_ingredients\", \"description_len\", \"n_steps\"]\n",
    "\n",
    "# make folds\n",
    "print(\"\\nCreating stratified folds via create_folds...\")\n",
    "create_folds(\n",
    "    input_data=data,\n",
    "    output_file=FOLDS_PATH,\n",
    "    text_columns=[\n",
    "        \"description_processed\"\n",
    "    ],  # creates \"document\" column, same as description_processed, but default name, so its easier to replicate\n",
    "    n_splits=N_SPLITS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# run K-Fold experiment with Linear SVC\n",
    "print(\"\\nRunning K-Fold experiment with Linear SVC on document + numeric features...\\n\")\n",
    "_ = run_kfold_experiment(\n",
    "    folds_file=FOLDS_PATH,\n",
    "    model_cls=SVC,\n",
    "    text_columns={\"document\": TFIDF_CFG},  # use the 'document' column created above\n",
    "    categorical_columns=None,\n",
    "    numerical_columns=numerical_features,  # ['n_ingredients','description_len','n_steps']\n",
    "    model_kwargs={\"kernel\": \"linear\", \"random_state\": RANDOM_SEED},\n",
    "    model_desc = \"Linear SVC (numerical data) | Text + Numerical | Unigrams + Bigrams, with term filtering\",\n",
    "    log_results=LOG_RESULTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97dc64d",
   "metadata": {},
   "source": [
    "### Categorical Features:\n",
    "\n",
    "Process the `tags` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41b8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading original dataset from 'data/train.csv'...\n",
      "Starting feature engineering...\n",
      "\n",
      "Preprocessing text data...\n",
      "\n",
      "Creating stratified folds via create_folds...\n",
      "\n",
      "==================================================\n",
      "## Chef ID Distribution Check\n",
      "\n",
      "=== Original Dataset === (Size: 2999)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       806       26.88\n",
      "5060       534       17.81\n",
      "3288       451       15.04\n",
      "8688       432       14.40\n",
      "1533       404       13.47\n",
      "6357       372       12.40\n",
      "\n",
      "=== Fold 1 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        86       14.33\n",
      "1533        81       13.50\n",
      "6357        75       12.50\n",
      "\n",
      "=== Fold 2 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       162       27.00\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        86       14.33\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 3 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        87       14.50\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 4 === (Size: 600)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.83\n",
      "5060       107       17.83\n",
      "3288        90       15.00\n",
      "8688        87       14.50\n",
      "1533        81       13.50\n",
      "6357        74       12.33\n",
      "\n",
      "=== Fold 5 === (Size: 599)\n",
      "         Count  Percentage\n",
      "chef_id                   \n",
      "4470       161       26.88\n",
      "5060       106       17.70\n",
      "3288        91       15.19\n",
      "8688        86       14.36\n",
      "1533        80       13.36\n",
      "6357        75       12.52\n",
      "==================================================\n",
      "\n",
      "Folds saved to 'data/feature_engineering/folds_allfeatures.csv' (Total: 2999 rows)\n",
      "\n",
      "Running K-Fold experiment with Linear SVC on document + numeric + tags features...\n",
      "\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.8533\n",
      "  Fold 2: 0.8567\n",
      "  Fold 3: 0.8383\n",
      "  Fold 4: 0.8417\n",
      "  Fold 5: 0.8564\n",
      "Mean accuracy: 0.8493  |  Std: 0.0087\n",
      "Total runtime: 3.13 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Text + Numerical + Categorical | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.svm import SVC\n",
    "from utils import run_kfold_experiment, create_folds\n",
    "\n",
    "# config\n",
    "ORIGINAL_DATA_PATH = \"data/train.csv\"\n",
    "FOLDS_PATH = \"data/feature_engineering/folds_allfeatures.csv\"\n",
    "\n",
    "# using best parameters identified from previous experiment for better performance\n",
    "TFIDF_CFG = {\n",
    "    \"ngram_range\": (1, 2),\n",
    "    \"min_df\": 5,\n",
    "    \"max_df\": 0.9,\n",
    "}\n",
    "\n",
    "# data loading and feature engineering\n",
    "print(f\"Loading original dataset from '{ORIGINAL_DATA_PATH}'...\")\n",
    "try:\n",
    "    data = pd.read_csv(ORIGINAL_DATA_PATH, sep=\";\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nERROR: Original data file not found at '{ORIGINAL_DATA_PATH}'.\")\n",
    "    exit()\n",
    "\n",
    "print(\"Starting feature engineering...\")\n",
    "\n",
    "# fill NaNs in key columns\n",
    "data[\"description\"] = data[\"description\"].fillna(\"\")\n",
    "data[\"steps\"] = data[\"steps\"].fillna(\"[]\")\n",
    "data[\"tags\"] = data[\"tags\"].fillna(\"[]\")\n",
    "data[\"n_ingredients\"] = data[\"n_ingredients\"].fillna(0)\n",
    "\n",
    "# create numerical features\n",
    "data[\"description_len\"] = data[\"description\"].str.len()\n",
    "data[\"n_steps\"] = data[\"steps\"].apply(lambda x: len(re.findall(r\"\\'(.*?)\\'\", str(x))))\n",
    "\n",
    "\n",
    "# define a function to parse the tags column (kept for consistency, helper has its own too)\n",
    "def parse_tags(tag_string):\n",
    "    try:\n",
    "        return re.findall(r\"\\'(.*?)\\'\", str(tag_string))\n",
    "    except (TypeError, ValueError):\n",
    "        return []\n",
    "\n",
    "\n",
    "# text preprocessing\n",
    "print(\"\\nPreprocessing text data...\")\n",
    "try:\n",
    "    stopwords.words(\"english\")\n",
    "except LookupError:\n",
    "    print(\"Stopwords not found. Downloading...\")\n",
    "    nltk.download(\"stopwords\")\n",
    "stop_words_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "data[\"description_processed\"] = (\n",
    "    data[\"description\"]\n",
    "    .str.lower()\n",
    "    .str.replace(r\"[^a-z\\s]\", \"\", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    "    .apply(lambda text: \" \".join([w for w in text.split() if w not in stop_words_set]))\n",
    ")\n",
    "\n",
    "numerical_features = [\"n_ingredients\", \"description_len\", \"n_steps\"]\n",
    "categorical_feature = \"tags\"  # will be parsed inside run_kfold_experiment\n",
    "text_feature = \"description_processed\"  # fed to create_folds -> 'document'\n",
    "\n",
    "# make folds\n",
    "print(\"\\nCreating stratified folds via create_folds...\")\n",
    "create_folds(\n",
    "    input_data=data,\n",
    "    output_file=FOLDS_PATH,\n",
    "    text_columns=[text_feature],  # creates 'document' from description_processed\n",
    "    n_splits=N_SPLITS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")\n",
    "\n",
    "# run K-Fold experiment with Linear SVC\n",
    "print(\n",
    "    \"\\nRunning K-Fold experiment with Linear SVC on document + numeric + tags features...\\n\"\n",
    ")\n",
    "_ = run_kfold_experiment(\n",
    "    folds_file=FOLDS_PATH,\n",
    "    model_cls=SVC,\n",
    "    text_columns={\"document\": TFIDF_CFG},  # use the 'document' column created above\n",
    "    categorical_columns=categorical_feature,  # 'tags' (helper will parse list-like strings)\n",
    "    numerical_columns=numerical_features,  # ['n_ingredients','description_len','n_steps']\n",
    "    model_kwargs={\"kernel\": \"linear\", \"random_state\": RANDOM_SEED},\n",
    "    model_desc=\"Linear SVC (allfeatures data) | Text + Numerical + Categorical | Unigrams + Bigrams, with term filtering\",\n",
    "    log_results=LOG_RESULTS,\n",
    "    random_seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f5554",
   "metadata": {},
   "source": [
    "## Mixing and matching\n",
    "\n",
    "To see what has the best results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e285f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.6650\n",
      "  Fold 2: 0.6283\n",
      "  Fold 3: 0.6817\n",
      "  Fold 4: 0.6550\n",
      "  Fold 5: 0.6728\n",
      "Mean accuracy: 0.6606  |  Std: 0.0205\n",
      "Total runtime: 2.64 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Text | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.3450\n",
      "  Fold 2: 0.3467\n",
      "  Fold 3: 0.3650\n",
      "  Fold 4: 0.3400\n",
      "  Fold 5: 0.3589\n",
      "Mean accuracy: 0.3511  |  Std: 0.0104\n",
      "Total runtime: 0.36 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Numerical'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.8117\n",
      "  Fold 2: 0.8083\n",
      "  Fold 3: 0.7900\n",
      "  Fold 4: 0.8050\n",
      "  Fold 5: 0.8047\n",
      "Mean accuracy: 0.8039  |  Std: 0.0083\n",
      "Total runtime: 2.07 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Categorical'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.6950\n",
      "  Fold 2: 0.6417\n",
      "  Fold 3: 0.7033\n",
      "  Fold 4: 0.6817\n",
      "  Fold 5: 0.6912\n",
      "Mean accuracy: 0.6826  |  Std: 0.0242\n",
      "Total runtime: 3.11 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Text + Numerical | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.8733\n",
      "  Fold 2: 0.8350\n",
      "  Fold 3: 0.8450\n",
      "  Fold 4: 0.8350\n",
      "  Fold 5: 0.8631\n",
      "Mean accuracy: 0.8503  |  Std: 0.0173\n",
      "Total runtime: 3.38 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Text + Categorical | Unigrams + Bigrams, with term filtering'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.8167\n",
      "  Fold 2: 0.8383\n",
      "  Fold 3: 0.8150\n",
      "  Fold 4: 0.8167\n",
      "  Fold 5: 0.8130\n",
      "Mean accuracy: 0.8199  |  Std: 0.0104\n",
      "Total runtime: 2.04 seconds\n",
      "==================================================\n",
      "➕ Added new results for 'Linear SVC (allfeatures data) | Numerical + Categorical'.\n",
      "✅ Results saved to results/log.xlsx\n",
      "==================================================\n",
      "Model: SVC\n",
      "Cross-Validation (using data/feature_engineering/folds_allfeatures.csv)\n",
      "  Fold 1: 0.8533\n",
      "  Fold 2: 0.8567\n",
      "  Fold 3: 0.8383\n",
      "  Fold 4: 0.8417\n",
      "  Fold 5: 0.8564\n",
      "Mean accuracy: 0.8493  |  Std: 0.0087\n",
      "Total runtime: 3.15 seconds\n",
      "==================================================\n",
      "⚠️ No changes for 'Linear SVC (allfeatures data) | Text + Numerical + Categorical | Unigrams + Bigrams, with term filtering', not updating log.\n",
      "\n",
      "================================================================================\n",
      "        SVC Accuracy by Feature Set (Top 10)\n",
      "================================================================================\n",
      "                                                                                                  Algorithm  Accuracy  Training_Time_s\n",
      "0              Linear SVC (allfeatures data) | Text + Categorical | Unigrams + Bigrams, with term filtering  0.850288         3.384474\n",
      "1  Linear SVC (allfeatures data) | Text + Numerical + Categorical | Unigrams + Bigrams, with term filtering  0.849285         3.153430\n",
      "2                                                   Linear SVC (allfeatures data) | Numerical + Categorical  0.819938         2.038831\n",
      "3                                                               Linear SVC (allfeatures data) | Categorical  0.803935         2.068213\n",
      "4                Linear SVC (allfeatures data) | Text + Numerical | Unigrams + Bigrams, with term filtering  0.682564         3.106611\n",
      "5                            Linear SVC (allfeatures data) | Text | Unigrams + Bigrams, with term filtering  0.660558         2.643008\n",
      "6                                                                 Linear SVC (allfeatures data) | Numerical  0.351120         0.356893\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from utils import run_configs, print_results_table\n",
    "import itertools\n",
    "\n",
    "# config\n",
    "FOLDS_PATH = \"data/feature_engineering/folds_allfeatures.csv\"\n",
    "\n",
    "tfidf_configs = [\n",
    "    {\n",
    "        \"description\": \"Unigrams + Bigrams, with term filtering\",\n",
    "        \"ngram_range\": (1, 2),\n",
    "        \"min_df\": 5,\n",
    "        \"max_df\": 0.9,\n",
    "    }\n",
    "]\n",
    "\n",
    "numerical_features = [\"n_ingredients\", \"description_len\", \"n_steps\"]\n",
    "categorical_feature = \"tags\"\n",
    "# text_column_name    = \"document\" # def, no need to add\n",
    "\n",
    "# all feature combinations\n",
    "features = [\"Text\", \"Numerical\", \"Categorical\"]\n",
    "feature_combinations = [\n",
    "    combo\n",
    "    for r in range(1, len(features) + 1)\n",
    "    for combo in itertools.combinations(features, r)\n",
    "]\n",
    "\n",
    "results = run_configs(\n",
    "    models=[(SVC, {\"kernel\": \"linear\"}, \"Linear SVC\")],\n",
    "    folds_path=FOLDS_PATH,\n",
    "    tfidf_configs=tfidf_configs,\n",
    "    feature_combinations=feature_combinations,\n",
    "    categorical_features=categorical_feature,\n",
    "    numerical_features=numerical_features,\n",
    "    random_seed=RANDOM_SEED,\n",
    "    log_results=LOG_RESULTS,\n",
    ")\n",
    "\n",
    "print_results_table(results, title=\"SVC Accuracy by Feature Set\", top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c2e2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
